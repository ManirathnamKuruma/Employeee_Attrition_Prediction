{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Department</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>EnvironmentSatisfaction</th>\n",
       "      <th>JobSatisfaction</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>NumCompaniesWorked</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>Attrition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>446</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>606</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>470</td>\n",
       "      <td>5993</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>961</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>606</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>673</td>\n",
       "      <td>5130</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>961</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>470</td>\n",
       "      <td>2090</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>961</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>606</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>673</td>\n",
       "      <td>2909</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>961</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>464</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>673</td>\n",
       "      <td>3468</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Department  DistanceFromHome  Education  EducationField  \\\n",
       "0   41         446                 1          2             606   \n",
       "1   49         961                 8          1             606   \n",
       "2   37         961                 2          2              82   \n",
       "3   33         961                 3          4             606   \n",
       "4   27         961                 2          1             464   \n",
       "\n",
       "   EnvironmentSatisfaction  JobSatisfaction  MaritalStatus  MonthlyIncome  \\\n",
       "0                        2                4            470           5993   \n",
       "1                        3                2            673           5130   \n",
       "2                        4                3            470           2090   \n",
       "3                        4                3            673           2909   \n",
       "4                        1                2            673           3468   \n",
       "\n",
       "   NumCompaniesWorked  WorkLifeBalance  YearsAtCompany  Attrition  \n",
       "0                   8                1               6          1  \n",
       "1                   1                3              10          0  \n",
       "2                   6                3               0          1  \n",
       "3                   1                3               8          0  \n",
       "4                   9                3               2          0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emp_df=pd.read_csv('processed_emp_data.csv')\n",
    "emp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identifying X and y\n",
    "X=emp_df.drop(['Attrition'],axis=1)\n",
    "y=emp_df['Attrition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1176, 12)\n",
      "(294, 12)\n",
      "(1176,)\n",
      "(294,)\n"
     ]
    }
   ],
   "source": [
    "# lets cross verfiy the result using train test split approach\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=21)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets fit the model\n",
    "from xgboost import XGBClassifier\n",
    "xgb_model=XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:44:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction on y\n",
    "y_train_pred=xgb_model.predict(X_train)\n",
    "y_test_pred=xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score of training data for xgb model:  1.0\n",
      "accuracy score of testing data for xgb model:  0.8197278911564626\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "#accuracy check on train and test data\n",
    "print('accuracy score of training data for xgb model: ',accuracy_score(y_train,y_train_pred))\n",
    "print('accuracy score of testing data for xgb model: ',accuracy_score(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:47:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Best: 0.693246 using {'scale_pos_weight': 1}\n",
      "0.693246 (0.046074) with: {'scale_pos_weight': 1}\n",
      "0.686451 (0.044591) with: {'scale_pos_weight': 10}\n",
      "0.677932 (0.040680) with: {'scale_pos_weight': 25}\n",
      "0.677805 (0.044262) with: {'scale_pos_weight': 50}\n",
      "0.676384 (0.052458) with: {'scale_pos_weight': 75}\n",
      "0.675247 (0.045056) with: {'scale_pos_weight': 99}\n",
      "0.676697 (0.048116) with: {'scale_pos_weight': 100}\n",
      "0.665723 (0.055153) with: {'scale_pos_weight': 1000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = XGBClassifier()\n",
    "# define grid\n",
    "weights = [1, 10, 25, 50, 75, 99, 100, 1000]\n",
    "param_grid = dict(scale_pos_weight=weights)\n",
    "# define evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define grid search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=cv, scoring='roc_auc')\n",
    "# execute the grid search\n",
    "grid_result = grid.fit(X, y)\n",
    "# report the best configuration\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "# report all configurations\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
